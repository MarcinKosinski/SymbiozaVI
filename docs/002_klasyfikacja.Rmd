---
title: "Klasyfikacja"
author: "Krzysztof Słomczyński"
date: "May 24, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Czym jest klasyfikacja?

Klasyfikacja polega na przewidywaniu **dyskretnej** zmiennej objaśnianej.

Przykładowe problemy klasyfikacji:

  - Czy wiadomość email jest spamem, czy nie?
  - Czy transakcja jest oszustwem, czy nie?
  - Czy nowotwór jest złośliwy, czy nie?

Najprostszą wersją tego zagadnienia jest klasyfikacja binarna, gdzie zmienna objaśniana Y z założenia może przyjąć tylko jedną z dwóch wartości -- Fałsz (0) lub Prawdę (1).

# Regresja liniowa w problemie klasyfikacji

```{r message = FALSE}
library(ggplot2)
```

```{r}
tumor <- data.frame(x = c(1:4, 6:9), y = c(rep(c(0, 1), each = 4)))
lm_model <- lm(formula = y ~ x, data = tumor)

plot(x = tumor$x,
     y = tumor$y,
     main = "Regresja liniowa – dobra?",
     xlab = "Rozmiar guza [j]",
     ylab = "Złośliwy?",
     xlim = c(0, 10),
     axes = FALSE)
axis(1, at = 0:10)
axis(2, at = c(0, 1))
curve(predict(object = lm_model, data.frame(x = x), type = "resp"),
      col = "blue", add = TRUE)
points(5, 0.5, cex = 2, col = "green", pch = "|")
lines(x = c(5, 5), y = c(0, 1), col = "red", lty = 2)

ggplot(data = tumor, mapping = aes(x = x, y = y)) +
  geom_point() +
  stat_smooth(method = "lm", col = "blue") +
  geom_point(mapping = aes(x = x, y = y),
             data = data.frame(x = 5, y = 0.5),
             cex = 8, col = "green", pch = "|") +
  geom_vline(xintercept = 5, col = "red", lty = 2) +
  scale_y_continuous(breaks = c(0, 1), labels = c("Nie", "Tak")) +
  labs(x = "Rozmiar guza [j]", y = "Złośliwy?") +
  ggtitle("Regresja liniowa – dobra?") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
tumor[9, ] <- c(20, 1)
lm_model <- lm(formula = y ~ x, data = tumor)

plot(x = tumor$x,
     y = tumor$y,
     main = "Regresja liniowa – nie dobra!",
     xlab = "Rozmiar guza [j]",
     ylab = "Złośliwy?",
     xlim = c(0, 20),
     axes = FALSE)
axis(1, at = 0:20)
axis(2, at = c(0, 1), labels = c("Nie", "Tak"))
curve(predict(object = lm_model, data.frame(x = x), type = "resp"),
      col = "blue", add = TRUE)
points(7, 0.575, cex = 2, col = "green", pch = "|")
lines(x = c(7, 7), y = c(0, 1), col = "red", lty = 2)

ggplot(data = tumor, mapping = aes(x = x, y = y)) +
  geom_point() +
  stat_smooth(method = "lm", col = "blue") +
  geom_point(mapping = aes(x = x, y = y),
             data = data.frame(x = 7, y = 0.575),
             cex = 8, col = "green", pch = "|") +
  geom_vline(xintercept = 7, col = "red", lty = 2) +
  scale_y_continuous(breaks = c(0, 1), labels = c("Nie", "Tak")) +
  labs(x = "Rozmiar guza [j]", y = "Złośliwy?") +
  ggtitle("Regresja liniowa – nie dobra!") +
  theme(plot.title = element_text(hjust = 0.5))
```

Dziwnym byłoby przewidywanie wartości Y wykraczającej poza przedział [0, 1], (poza "Nie" i "Tak").

# Regresja logistyczna

Najpopularniejszym algorytmem służącym do rozwiązywania problemów klasyfikacji jest **regresja logistyczna**. Wykorzystuje ona funkcję sigmoidalną zadaną wzorem $g(z) = \frac{1}{1 + e^{-x}}$.

```{r}
glm_model <- glm(formula = y ~ x, family = binomial, data = tumor)

plot(x = tumor$x,
     y = tumor$y,
     main = "Regresja logistyczna",
     xlab = "Rozmiar guza [j]",
     ylab = "Złośliwy?",
     xlim = c(0, 20),
     axes = FALSE)
axis(1, at = 0:20)
axis(2, at = c(0, 1), labels = c("Nie", "Tak"))
curve(predict(object = glm_model, data.frame(x = x), type = "resp"),
      col = "blue", add = TRUE)
points(5, 0.5, cex = 2, col = "green", pch = "|")

ggplot(data = tumor, mapping = aes(x = x, y = y)) +
  geom_point() +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              col = "blue") +
  geom_point(mapping = aes(x = x, y = y),
             data = data.frame(x = 5, y = 0.5),
             cex = 8, col = "green", pch = "|") +
  geom_vline(xintercept = 5, col = "red", lty = 2) +
  scale_y_continuous(breaks = c(0, 1), labels = c("Nie", "Tak")) +
  labs(x = "Rozmiar guza [j]", y = "Złośliwy?") +
  ggtitle("Regresja logistyczna") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Operacje na danych biologicznych.

`broom` -- pakiet ułatwiający korzystanie z modeli otrzymanych za pomocą podstawowego pakietu `stats`.

`caret` -- pakiet ujednolicający środowisko pracy w uczeniu statystycznym.

```{r}
library(broom)
library(caret)
```

## Podział danych na dwa zestawy -- treningowy i testowy.

Na zestawie treningowym wyszkolimy model regresji logistycznej, który wypróbujemy później na zbiorze testowym. W przygotowaniu zbiorów pomoże nam funkcja `createDataPartition` z pakietu `caret`. Dzięki niej mamy pewność, że unikniemy przypadkowego przydzielenia np. wszystkich zmarłych pacjentów tylko i wyłącznie do jednego z zestawów. Na początek przyjrzyjmy się, czy chcemy budować model na wszystkich dostępnych zmiennych w ramce danych. We wstępnej selekcji również pomogą nam funkcje z pakietu `caret`.

```{r}
data_set <- read.csv("../data/bio_data.csv")

# Pozbycie się niepełnych obserwacji i identyfikatora
data_set <- data_set[complete.cases(data_set),
                     colnames(data_set) != "bcr_patient_barcode"]

# Sprawdzenie, czy któreś ze zmiennych objaśniajacych nie posiadają wariancji bliskiej zeru
near_zero_var <- nearZeroVar(x = data_set, saveMetrics = TRUE)
near_zero_var

# Sprawdzenie, czy niektóre zmienne nie są ze sobą silnie skorelowane
matrix_set <- data.matrix(data_set)
correlation <- cor(matrix_set)
summary(correlation[upper.tri(correlation)])
find_correlation <- findCorrelation(correlation, cutoff = .5,
                                    verbose = TRUE, names = TRUE)
find_correlation

# Sprawdzenie liniowych zależności
comboInfo <- findLinearCombos(matrix_set)
comboInfo
```

```{r}
set.seed(42)
train_rows <- createDataPartition(y = data_set$status, p = 0.8, list = FALSE)
train <- data_set[train_rows, ]
test <- data_set[-train_rows, ]
```

## Szkolenie modelu

Kropka w formule oznacza, że chcemy stworzyć model od wszystkich dostępnych zmiennych objaśniających.

```{r}
glm_model <- glm(formula = status ~ ., data = train)
```

Przyjrzyjmy się wyszkolonemu modelowi

```{r}
glm_model
```

Informacje nie są zbyt czytelne. W celu ujednolicenia informacji o modelu posłużymy się funkcjami z pakietu `broom`.

```{r}
glm_tidy <- tidy(glm_model)
glm_tidy
glm_glance <- glance(glm_model)
glm_glance
```

Możemy zauważyć, że ciągła zmienna objaśniająca `times` występuje tylko raz, natomiast każda dyskretna zmienna objaśniająca (np. `cancer`) została zastąpiona o jedną mniej zmienną (w tym wypadku dwoma) niż posiadała pierwotnie. Każda z tych nowych zmiennych (tzw. dummy variables) przybierają wartości 0 i 1 (dla danej obserwacji wystąpił dany typ raka, albo nie wystąpił). Wariantowi z trzecią -- brakującą zmienną odpowiada sytuacja, w której wszystkie nowopowstałe zmienne (od danej zmiennej) przyjmuja wartość 0.

```{r}
prediction <- predict(object = glm_model, newdata = test, type = "response")
prediction <- round(x = prediction, digits = 0)
prediction_frame <- data.frame(actual = test$status, predicted = prediction,
                               row.names = 1:length(test$status))
prediction_frame <- sapply(X = prediction_frame, FUN = plyr::mapvalues,
                           from = c(0, 1), to = c("Survived", "Passed"))
prediction_frame <- as.data.frame(prediction_frame)
confusion_matrix <- table(prediction_frame$predicted, prediction_frame$actual,
                          dnn = c("predicted", "actual"))
confusion_matrix <- confusionMatrix(confusion_matrix, positive = "Passed")
glm_score <- confusion_matrix$byClass["Sensitivity"] +
  confusion_matrix$byClass["Specificity"]
glm_score <- unname(glm_score)
glm_score
unname(glm_score/2 == confusion_matrix$byClass["Balanced Accuracy"])
```

Wizualizacja macierzy pomyłek.

```{r}
actual_class <- rep(dimnames(confusion_matrix$table)$actual,
                    each = 2)
prediction_class <- rep(dimnames(confusion_matrix$table)$predicted,
                        times = 2)
label <- paste(c("True Positive", "False Negative",
                 "False Positive", "True Negative"),
               as.vector(confusion_matrix$table),
               sep = "\n")
fill <- c("green", "red", "red", "green")
confusion_frame <- data.frame(actual = actual_class,
                              prediction = prediction_class,
                              label = label,
                              fill = fill)

ggplot(data =  confusion_frame,
       mapping = aes(x = actual, y = prediction, fill = fill,
                     label = label)) +
  geom_tile() +
  geom_text() +
  scale_fill_identity() +
  scale_x_discrete(position = "top") +
  scale_y_discrete(limits = rev(levels(confusion_frame$prediction))) +
  ggtitle("Macierz pomyłek") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

Parametrów wynikających z macierzy pomyłek jest znacznie więcej. Skupimy się na dwóch poniższych i to za ich pomocą będziemy oceniać skuteczność naszego modelu.

- True Positive Rate -- TPR, Sensitivity

    $True Positive Rate = \frac{True Positive}{True Positive + False Negative}$
    
- True Negative Rate -- TNR, Specificity

    $True Negative Rate = \frac{True Negative}{True Negative + False Positive}$

Oba te parametry uwzględniają liczebność swoich klas, co jest **bardzo** istotne w ocenie modelu. W naszym przypadku klasy różnią się od siebie liczebnością w znaczącym stopniu (zmarło 40 pacjentów, przeżyło 205). Zauważmy, że naiwnie zakładając przeżycie każdego pacjenta otrzymujemy aż 205 trafnych predykcji z 245 uzyskując tylko pozornie lepszy model. Dlatego tak **bardzo** ważne jest uwzględnienie liczebności klas.

```{r}
205/245
glm_score/2
205/245 > glm_score/2
```

# Kroswalidacja

